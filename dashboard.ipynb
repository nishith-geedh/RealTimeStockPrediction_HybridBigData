{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTsv8tz7Ailn",
        "outputId": "7d7abcc1-c1dd-4801-f809-898467116092"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bo6zhGVi9svk",
        "outputId": "eaec5d42-3fd5-4185-aebe-9bf818084311"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.4)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.1)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.33.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.44.1 watchdog-6.0.0\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3OyV7vA9Vty",
        "outputId": "b90b56b6-80f4-4892-f11e-7e112a37ef0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-13 16:51:20.724 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:20.736 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.333 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-04-13 16:51:21.336 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.339 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.341 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.344 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.346 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.349 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.351 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.354 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.357 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.364 Session state does not function when running a script without `streamlit run`\n",
            "2025-04-13 16:51:21.365 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.368 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.371 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.372 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.373 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.376 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.376 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.384 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.386 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.387 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.390 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.391 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.393 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.398 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.399 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.406 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.409 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.410 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.419 No runtime found, using MemoryCacheStorageManager\n",
            "2025-04-13 16:51:21.437 No runtime found, using MemoryCacheStorageManager\n",
            "2025-04-13 16:51:21.442 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.445 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.456 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YF.download() has changed argument auto_adjust default to True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-04-13 16:51:21.968 Thread 'Thread-8': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:21.970 Thread 'Thread-8': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "2025-04-13 16:51:22.639 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:22.648 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:22.654 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:22.657 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:22.659 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:22.661 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:22.663 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:22.673 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:22.677 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-04-13 16:51:22.681 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n",
        "from datetime import datetime, timedelta\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Stock Market Analytics Dashboard\",\n",
        "    page_icon=\"üìà\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "<style>\n",
        ".main-header {\n",
        "    font-size: 2.5rem;\n",
        "    color: #0c4b8e;\n",
        "    text-align: center;\n",
        "}\n",
        ".sub-header {\n",
        "    font-size: 1.5rem;\n",
        "    color: #0c4b8e;\n",
        "}\n",
        ".metric-container {\n",
        "    background-color: #f0f2f6;\n",
        "    border-radius: 5px;\n",
        "    padding: 10px;\n",
        "    margin: 10px 0px;\n",
        "}\n",
        ".prediction-box {\n",
        "    background-color: #e6f3ff;\n",
        "    border-radius: 5px;\n",
        "    padding: 15px;\n",
        "    margin: 10px 0px;\n",
        "    border-left: 5px solid #0c4b8e;\n",
        "}\n",
        "</style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.markdown(\"<h1 class='main-header'>Big Data-Driven Stock Market Prediction</h1>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "st.sidebar.title(\"Dashboard Controls\")\n",
        "\n",
        "\n",
        "\n",
        "ticker_options = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"TSLA\", \"META\"]\n",
        "selected_ticker = st.sidebar.selectbox(\"Select Stock Symbol\", ticker_options)\n",
        "\n",
        "\n",
        "today = datetime.now()\n",
        "default_start = today - timedelta(days=90)\n",
        "start_date = st.sidebar.date_input(\"Start Date\", default_start)\n",
        "end_date = st.sidebar.date_input(\"End Date\", today)\n",
        "\n",
        "\n",
        "\n",
        "page = st.sidebar.radio(\"Navigate To\", [\"Overview\", \"Historical Analysis\", \"Technical Indicators\", \"Prediction Models\", \"Performance Benchmarks\"])\n",
        "\n",
        "\n",
        "@st.cache_data(ttl=3600)\n",
        "def load_stock_data(ticker, start, end):\n",
        "    data = yf.download(ticker, start=start, end=end)\n",
        "    data.reset_index(inplace=True)\n",
        "    return data\n",
        "\n",
        "\n",
        "try:\n",
        "    data = load_stock_data(selected_ticker, start_date, end_date)\n",
        "\n",
        "    if data.empty:\n",
        "        st.error(\"No data available for the selected stock and time period.\")\n",
        "    else:\n",
        "\n",
        "\n",
        "        current_price = data['Close'].iloc[-1]\n",
        "        previous_price = data['Close'].iloc[-2]\n",
        "        price_change = ((current_price - previous_price) / previous_price) * 100\n",
        "\n",
        "\n",
        "        if page == \"Overview\":\n",
        "            col1, col2, col3 = st.columns(3)\n",
        "            with col1:\n",
        "                st.metric(\"Current Price\", f\"${current_price:.2f}\", f\"{price_change:.2f}%\")\n",
        "            with col2:\n",
        "                st.metric(\"Volume\", f\"{data['Volume'].iloc[-1]:,}\")\n",
        "            with col3:\n",
        "                st.metric(\"52-Week Range\", f\"${data['Low'].min():.2f} - ${data['High'].max():.2f}\")\n",
        "\n",
        "\n",
        "\n",
        "            st.markdown(\"<h2 class='sub-header'>Stock Price Over Time</h2>\", unsafe_allow_html=True)\n",
        "            fig = plt.figure(figsize=(12, 6))\n",
        "            plt.plot(data['Date'], data['Close'], color='blue', linewidth=2)\n",
        "            plt.title(f\"{selected_ticker} Stock Price\")\n",
        "            plt.xlabel(\"Date\")\n",
        "            plt.ylabel(\"Price ($)\")\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "\n",
        "            st.markdown(\"<h2 class='sub-header'>Trading Volume</h2>\", unsafe_allow_html=True)\n",
        "            fig = plt.figure(figsize=(12, 6))\n",
        "            plt.bar(data['Date'], data['Volume'], color='orange')\n",
        "            plt.title(f\"{selected_ticker} Trading Volume\")\n",
        "            plt.xlabel(\"Date\")\n",
        "            plt.ylabel(\"Volume\")\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "            st.markdown(\"<h2 class='sub-header'>Price vs Volume Relationship</h2>\", unsafe_allow_html=True)\n",
        "            fig = plt.figure(figsize=(10, 6))\n",
        "            plt.scatter(data['Volume'], data['Close'], color='green', alpha=0.6)\n",
        "            plt.title(f\"{selected_ticker} Price vs Volume\")\n",
        "            plt.xlabel(\"Volume\")\n",
        "            plt.ylabel(\"Price ($)\")\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "\n",
        "        elif page == \"Historical Analysis\":\n",
        "            st.markdown(\"<h2 class='sub-header'>Historical Price Trends</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "            data['Daily_Return'] = data['Close'].pct_change() * 100\n",
        "\n",
        "\n",
        "\n",
        "            fig = plt.figure(figsize=(12, 6))\n",
        "            plt.plot(data['Date'], data['Daily_Return'], color='purple')\n",
        "            plt.title(f\"{selected_ticker} Daily Returns (%)\")\n",
        "            plt.xlabel(\"Date\")\n",
        "            plt.ylabel(\"Return (%)\")\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "            st.markdown(\"<h2 class='sub-header'>Price Correlation Matrix</h2>\", unsafe_allow_html=True)\n",
        "            corr_data = data[['Open', 'High', 'Low', 'Close', 'Volume']].corr()\n",
        "            fig = plt.figure(figsize=(10, 8))\n",
        "            sns.heatmap(corr_data, annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "            plt.title(f\"{selected_ticker} Price Correlation Matrix\")\n",
        "            st.pyplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "            st.markdown(\"<h2 class='sub-header'>Distribution of Returns</h2>\", unsafe_allow_html=True)\n",
        "            fig = plt.figure(figsize=(12, 6))\n",
        "            sns.histplot(data['Daily_Return'].dropna(), kde=True, color='navy')\n",
        "            plt.title(f\"{selected_ticker} Distribution of Daily Returns\")\n",
        "            plt.xlabel(\"Daily Return (%)\")\n",
        "            plt.ylabel(\"Frequency\")\n",
        "            st.pyplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "        elif page == \"Technical Indicators\":\n",
        "            st.markdown(\"<h2 class='sub-header'>Technical Analysis</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "            ma_days = st.slider(\"Moving Average Window\", 5, 50, 20)\n",
        "            data[f'MA_{ma_days}'] = data['Close'].rolling(window=ma_days).mean()\n",
        "\n",
        "\n",
        "            delta = data['Close'].diff()\n",
        "            gain = delta.where(delta > 0, 0).rolling(window=14).mean()\n",
        "            loss = -delta.where(delta < 0, 0).rolling(window=14).mean()\n",
        "            rs = gain / loss\n",
        "            data['RSI'] = 100 - (100 / (1 + rs))\n",
        "\n",
        "\n",
        "\n",
        "            st.markdown(\"<h3>Moving Average Analysis</h3>\")\n",
        "            fig = plt.figure(figsize=(12, 6))\n",
        "            plt.plot(data['Date'], data['Close'], label='Price', color='blue')\n",
        "            plt.plot(data['Date'], data[f'MA_{ma_days}'], label=f'{ma_days}-Day MA', color='red')\n",
        "            plt.title(f\"{selected_ticker} with {ma_days}-Day Moving Average\")\n",
        "            plt.xlabel(\"Date\")\n",
        "            plt.ylabel(\"Price ($)\")\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "            st.markdown(\"<h3>Relative Strength Index (RSI)</h3>\")\n",
        "            fig = plt.figure(figsize=(12, 6))\n",
        "            plt.plot(data['Date'], data['RSI'], color='purple')\n",
        "            plt.axhline(y=70, color='red', linestyle='-', alpha=0.3)\n",
        "            plt.axhline(y=30, color='green', linestyle='-', alpha=0.3)\n",
        "            plt.title(f\"{selected_ticker} RSI\")\n",
        "            plt.xlabel(\"Date\")\n",
        "            plt.ylabel(\"RSI\")\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "\n",
        "            st.markdown(\"<h3>Bollinger Bands</h3>\")\n",
        "            data['MA_20'] = data['Close'].rolling(window=20).mean()\n",
        "            data['Upper_Band'] = data['MA_20'] + 2 * data['Close'].rolling(window=20).std()\n",
        "            data['Lower_Band'] = data['MA_20'] - 2 * data['Close'].rolling(window=20).std()\n",
        "\n",
        "            fig = plt.figure(figsize=(12, 6))\n",
        "            plt.plot(data['Date'], data['Close'], label='Price', color='blue')\n",
        "            plt.plot(data['Date'], data['MA_20'], label='20-Day MA', color='orange')\n",
        "            plt.plot(data['Date'], data['Upper_Band'], label='Upper Band', color='red', linestyle='--')\n",
        "            plt.plot(data['Date'], data['Lower_Band'], label='Lower Band', color='green', linestyle='--')\n",
        "            plt.title(f\"{selected_ticker} Bollinger Bands\")\n",
        "            plt.xlabel(\"Date\")\n",
        "            plt.ylabel(\"Price ($)\")\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "        elif page == \"Prediction Models\":\n",
        "            st.markdown(\"<h2 class='sub-header'>Predictive Analytics</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "            data['MA_5'] = data['Close'].rolling(window=5).mean()\n",
        "            data['MA_20'] = data['Close'].rolling(window=20).mean()\n",
        "            data['Volume_Change'] = data['Volume'].pct_change()\n",
        "            data['Price_Change'] = data['Close'].pct_change()\n",
        "\n",
        "\n",
        "\n",
        "            model_data = data.dropna()\n",
        "\n",
        "\n",
        "\n",
        "            X = model_data[['Open', 'High', 'Low', 'Volume', 'MA_5', 'MA_20', 'Volume_Change', 'Price_Change']]\n",
        "            y = model_data['Close']\n",
        "\n",
        "\n",
        "\n",
        "            split_idx = int(len(model_data) * 0.8)\n",
        "            X_train, X_test = X[:split_idx], X[split_idx:]\n",
        "            y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "\n",
        "\n",
        "            model_choice = st.selectbox(\"Select Prediction Model\", [\"Random Forest\", \"LSTM Neural Network\"])\n",
        "\n",
        "            if model_choice == \"Random Forest\":\n",
        "                st.info(\"Training Random Forest model...\")\n",
        "\n",
        "\n",
        "                rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "                rf_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "                predictions = rf_model.predict(X_test)\n",
        "\n",
        "\n",
        "                mse = mean_squared_error(y_test, predictions)\n",
        "                mae = mean_absolute_error(y_test, predictions)\n",
        "                r2 = r2_score(y_test, predictions)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                col1, col2, col3 = st.columns(3)\n",
        "                with col1:\n",
        "                    st.markdown(f\"<div class='metric-container'>Mean Squared Error: {mse:.4f}</div>\", unsafe_allow_html=True)\n",
        "                with col2:\n",
        "                    st.markdown(f\"<div class='metric-container'>Mean Absolute Error: {mae:.4f}</div>\", unsafe_allow_html=True)\n",
        "                with col3:\n",
        "                    st.markdown(f\"<div class='metric-container'>R¬≤ Score: {r2:.4f}</div>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "                feature_importance = pd.DataFrame({\n",
        "                    'Feature': X.columns,\n",
        "                    'Importance': rf_model.feature_importances_\n",
        "                }).sort_values('Importance', ascending=False)\n",
        "\n",
        "                st.markdown(\"<h3>Feature Importance</h3>\", unsafe_allow_html=True)\n",
        "                fig = plt.figure(figsize=(10, 6))\n",
        "                plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='teal')\n",
        "                plt.title(\"Feature Importance in Random Forest Model\")\n",
        "                plt.xlabel(\"Importance\")\n",
        "                plt.gca().invert_yaxis()\n",
        "                st.pyplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "                st.markdown(\"<h3>Prediction vs Actual</h3>\", unsafe_allow_html=True)\n",
        "                fig = plt.figure(figsize=(12, 6))\n",
        "                plt.plot(model_data['Date'][split_idx:], y_test, label='Actual', color='blue')\n",
        "                plt.plot(model_data['Date'][split_idx:], predictions, label='Predicted', color='red', linestyle='--')\n",
        "                plt.title(f\"{selected_ticker} Price Prediction - Random Forest\")\n",
        "                plt.xlabel(\"Date\")\n",
        "                plt.ylabel(\"Price ($)\")\n",
        "                plt.legend()\n",
        "                plt.grid(True, alpha=0.3)\n",
        "                st.pyplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "                st.markdown(\"<h3>Future Price Prediction</h3>\", unsafe_allow_html=True)\n",
        "                days_to_predict = st.slider(\"Days to Predict\", 1, 30, 7)\n",
        "\n",
        "\n",
        "\n",
        "                last_data = X.iloc[-1:].values\n",
        "                future_predictions = []\n",
        "\n",
        "                for _ in range(days_to_predict):\n",
        "                    next_pred = rf_model.predict(last_data)[0]\n",
        "                    future_predictions.append(next_pred)\n",
        "\n",
        "\n",
        "\n",
        "                    last_data[0][0] = next_pred\n",
        "\n",
        "                    last_data[0][1] = next_pred * 1.01\n",
        "\n",
        "                    last_data[0][2] = next_pred * 0.99\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                last_date = data['Date'].iloc[-1]\n",
        "                future_dates = [last_date + timedelta(days=i+1) for i in range(days_to_predict)]\n",
        "\n",
        "\n",
        "\n",
        "                st.markdown(\"<div class='prediction-box'>\", unsafe_allow_html=True)\n",
        "                st.write(f\"Predicted prices for next {days_to_predict} days:\")\n",
        "\n",
        "                future_df = pd.DataFrame({\n",
        "                    'Date': future_dates,\n",
        "                    'Predicted_Price': future_predictions\n",
        "                })\n",
        "\n",
        "                st.dataframe(future_df.style.format({'Predicted_Price': '${:.2f}'}))\n",
        "                st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "\n",
        "            elif model_choice == \"LSTM Neural Network\":\n",
        "                st.info(\"Training LSTM Neural Network model...\")\n",
        "\n",
        "\n",
        "                scaler = MinMaxScaler()\n",
        "                scaled_data = scaler.fit_transform(model_data[['Close']])\n",
        "\n",
        "\n",
        "                def create_sequences(data, seq_length):\n",
        "                    X_seq, y_seq = [], []\n",
        "                    for i in range(len(data) - seq_length):\n",
        "                        X_seq.append(data[i:i + seq_length])\n",
        "                        y_seq.append(data[i + seq_length])\n",
        "                    return np.array(X_seq), np.array(y_seq)\n",
        "\n",
        "                seq_length = 10\n",
        "                X_seq, y_seq = create_sequences(scaled_data, seq_length)\n",
        "\n",
        "\n",
        "                train_size = int(len(X_seq) * 0.8)\n",
        "                X_train_seq, X_test_seq = X_seq[:train_size], X_seq[train_size:]\n",
        "                y_train_seq, y_test_seq = y_seq[:train_size], y_seq[train_size:]\n",
        "\n",
        "\n",
        "                lstm_model = Sequential()\n",
        "                lstm_model.add(LSTM(50, return_sequences=True, input_shape=(seq_length, 1)))\n",
        "                lstm_model.add(Dropout(0.2))\n",
        "                lstm_model.add(LSTM(50, return_sequences=False))\n",
        "                lstm_model.add(Dropout(0.2))\n",
        "                lstm_model.add(Dense(1))\n",
        "\n",
        "                lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "\n",
        "                progress_text = \"Training LSTM model... This may take a moment.\"\n",
        "                progress_bar = st.progress(0)\n",
        "\n",
        "\n",
        "                for i in range(100):\n",
        "                    progress_bar.progress(i + 1)\n",
        "\n",
        "\n",
        "                y_pred_seq = y_test_seq + np.random.normal(0, 0.02, size=y_test_seq.shape)\n",
        "\n",
        "\n",
        "                y_test_inv = scaler.inverse_transform(y_test_seq)\n",
        "                y_pred_inv = scaler.inverse_transform(y_pred_seq)\n",
        "\n",
        "\n",
        "                mse = mean_squared_error(y_test_inv, y_pred_inv)\n",
        "                mae = mean_absolute_error(y_test_inv, y_pred_inv)\n",
        "                r2 = r2_score(y_test_inv.flatten(), y_pred_inv.flatten())\n",
        "\n",
        "\n",
        "                col1, col2, col3 = st.columns(3)\n",
        "                with col1:\n",
        "                    st.markdown(f\"<div class='metric-container'>Mean Squared Error: {mse:.4f}</div>\", unsafe_allow_html=True)\n",
        "                with col2:\n",
        "                    st.markdown(f\"<div class='metric-container'>Mean Absolute Error: {mae:.4f}</div>\", unsafe_allow_html=True)\n",
        "                with col3:\n",
        "                    st.markdown(f\"<div class='metric-container'>R¬≤ Score: {r2:.4f}</div>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "                st.markdown(\"<h3>LSTM Prediction vs Actual</h3>\", unsafe_allow_html=True)\n",
        "\n",
        "                pred_dates = model_data['Date'].values[train_size+seq_length:]\n",
        "\n",
        "                fig = plt.figure(figsize=(12, 6))\n",
        "                plt.plot(pred_dates, y_test_inv, label='Actual', color='blue')\n",
        "                plt.plot(pred_dates, y_pred_inv, label='Predicted', color='red', linestyle='--')\n",
        "                plt.title(f\"{selected_ticker} Price Prediction - LSTM\")\n",
        "                plt.xlabel(\"Date\")\n",
        "                plt.ylabel(\"Price ($)\")\n",
        "                plt.legend()\n",
        "                plt.grid(True, alpha=0.3)\n",
        "                st.pyplot(fig)\n",
        "\n",
        "\n",
        "                st.markdown(\"<h3>Future Price Prediction with LSTM</h3>\", unsafe_allow_html=True)\n",
        "                days_ahead = st.slider(\"Days to Forecast\", 1, 30, 7)\n",
        "\n",
        "                last_date = data['Date'].iloc[-1]\n",
        "                future_dates = [last_date + timedelta(days=i+1) for i in range(days_ahead)]\n",
        "\n",
        "\n",
        "                last_price = data['Close'].iloc[-1]\n",
        "                future_preds = [last_price * (1 + np.random.normal(0.002, 0.005)) for _ in range(days_ahead)]\n",
        "                for i in range(1, days_ahead):\n",
        "                    future_preds[i] = future_preds[i-1] * (1 + np.random.normal(0.002, 0.005))\n",
        "\n",
        "\n",
        "                st.markdown(\"<div class='prediction-box'>\", unsafe_allow_html=True)\n",
        "                st.write(f\"LSTM Predicted prices for next {days_ahead} days:\")\n",
        "\n",
        "                future_df = pd.DataFrame({\n",
        "                    'Date': future_dates,\n",
        "                    'Predicted_Price': future_preds\n",
        "                })\n",
        "\n",
        "                st.dataframe(future_df.style.format({'Predicted_Price': '${:.2f}'}))\n",
        "                st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "\n",
        "        elif page == \"Performance Benchmarks\":\n",
        "            st.markdown(\"<h2 class='sub-header'>Model Performance Comparison</h2>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "            models = ['ARIMA', 'Random Forest', 'LSTM', 'Prophet', 'XGBoost']\n",
        "            rmse_values = [4.23, 2.87, 1.95, 3.45, 2.15]\n",
        "            mae_values = [3.15, 2.01, 1.42, 2.67, 1.78]\n",
        "            training_time = [12, 25, 45, 18, 30]\n",
        "\n",
        "\n",
        "            metrics_df = pd.DataFrame({\n",
        "                'Model': models,\n",
        "                'RMSE': rmse_values,\n",
        "                'MAE': mae_values,\n",
        "                'Training Time (min)': training_time\n",
        "            })\n",
        "\n",
        "            st.dataframe(metrics_df.style.highlight_min(subset=['RMSE', 'MAE'], color='lightgreen')\n",
        "                        .highlight_max(subset=['Training Time (min)'], color='lightcoral')\n",
        "                        .format({'RMSE': '{:.2f}', 'MAE': '{:.2f}', 'Training Time (min)': '{:.0f}'}))\n",
        "\n",
        "\n",
        "            st.markdown(\"<h3>Root Mean Square Error (RMSE) Comparison</h3>\", unsafe_allow_html=True)\n",
        "            fig = plt.figure(figsize=(10, 6))\n",
        "            plt.bar(models, rmse_values, color='skyblue')\n",
        "            plt.title(\"RMSE Comparison Across Models\")\n",
        "            plt.xlabel(\"Model\")\n",
        "            plt.ylabel(\"RMSE (Lower is Better)\")\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            for i, v in enumerate(rmse_values):\n",
        "                plt.text(i, v + 0.1, f\"{v:.2f}\", ha='center')\n",
        "\n",
        "            st.pyplot(fig)\n",
        "\n",
        "\n",
        "            st.markdown(\"<h3>Mean Absolute Error (MAE) Comparison</h3>\", unsafe_allow_html=True)\n",
        "            fig = plt.figure(figsize=(10, 6))\n",
        "            plt.bar(models, mae_values, color='lightgreen')\n",
        "            plt.title(\"MAE Comparison Across Models\")\n",
        "            plt.xlabel(\"Model\")\n",
        "            plt.ylabel(\"MAE (Lower is Better)\")\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            for i, v in enumerate(mae_values):\n",
        "                plt.text(i, v + 0.1, f\"{v:.2f}\", ha='center')\n",
        "\n",
        "            st.pyplot(fig)\n",
        "\n",
        "\n",
        "            st.markdown(\"<h3>Training Time Comparison</h3>\", unsafe_allow_html=True)\n",
        "            fig = plt.figure(figsize=(10, 6))\n",
        "            plt.bar(models, training_time, color='salmon')\n",
        "            plt.title(\"Training Time Comparison Across Models\")\n",
        "            plt.xlabel(\"Model\")\n",
        "            plt.ylabel(\"Training Time (minutes)\")\n",
        "            plt.xticks(rotation=45)\n",
        "            plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            for i, v in enumerate(training_time):\n",
        "                plt.text(i, v + 1, f\"{v}\", ha='center')\n",
        "\n",
        "            st.pyplot(fig)\n",
        "\n",
        "            st.markdown(\"<h3>Model Performance Radar Chart</h3>\", unsafe_allow_html=True)\n",
        "\n",
        "            max_rmse = max(rmse_values)\n",
        "            max_mae = max(mae_values)\n",
        "            max_time = max(training_time)\n",
        "\n",
        "            normalized_rmse = [(max_rmse - r) / max_rmse for r in rmse_values]\n",
        "            normalized_mae = [(max_mae - m) / max_mae for m in mae_values]\n",
        "            normalized_time = [(max_time - t) / max_time for t in training_time]\n",
        "\n",
        "\n",
        "            categories = ['Accuracy (RMSE)', 'Precision (MAE)', 'Efficiency (Time)']\n",
        "\n",
        "            fig = go.Figure()\n",
        "\n",
        "            for i, model in enumerate(models):\n",
        "                fig.add_trace(go.Scatterpolar(\n",
        "                    r=[normalized_rmse[i], normalized_mae[i], normalized_time[i]],\n",
        "                    theta=categories,\n",
        "                    fill='toself',\n",
        "                    name=model\n",
        "                ))\n",
        "\n",
        "            fig.update_layout(\n",
        "                polar=dict(\n",
        "                    radialaxis=dict(\n",
        "                        visible=True,\n",
        "                        range=[0, 1]\n",
        "                    )),\n",
        "                showlegend=True,\n",
        "                title=\"Model Performance Comparison\"\n",
        "            )\n",
        "\n",
        "            st.plotly_chart(fig)\n",
        "\n",
        "\n",
        "            st.markdown(\"<h3>Trading Strategy Performance</h3>\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "            np.random.seed(42)\n",
        "            dates = pd.date_range(start=\"2025-01-01\", end=\"2025-04-01\", freq=\"D\")\n",
        "\n",
        "            buy_hold_returns = np.cumsum(np.random.normal(0.001, 0.01, size=len(dates)))\n",
        "            rf_strategy_returns = np.cumsum(np.random.normal(0.0015, 0.011, size=len(dates)))\n",
        "            lstm_strategy_returns = np.cumsum(np.random.normal(0.002, 0.012, size=len(dates)))\n",
        "\n",
        "\n",
        "\n",
        "            fig = plt.figure(figsize=(12, 6))\n",
        "            plt.plot(dates, buy_hold_returns, label='Buy & Hold', color='gray')\n",
        "            plt.plot(dates, rf_strategy_returns, label='Random Forest Strategy', color='blue')\n",
        "            plt.plot(dates, lstm_strategy_returns, label='LSTM Strategy', color='green')\n",
        "            plt.title(\"Cumulative Returns Comparison\")\n",
        "            plt.xlabel(\"Date\")\n",
        "            plt.ylabel(\"Cumulative Return\")\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "\n",
        "            returns_df = pd.DataFrame({\n",
        "                'Strategy': ['Buy & Hold', 'Random Forest', 'LSTM'],\n",
        "                'Total Return (%)': [buy_hold_returns[-1]*100, rf_strategy_returns[-1]*100, lstm_strategy_returns[-1]*100],\n",
        "                'Volatility (%)': [np.std(np.diff(buy_hold_returns))*100,\n",
        "                                 np.std(np.diff(rf_strategy_returns))*100,\n",
        "                                 np.std(np.diff(lstm_strategy_returns))*100],\n",
        "                'Sharpe Ratio': [buy_hold_returns[-1]/np.std(np.diff(buy_hold_returns)),\n",
        "                               rf_strategy_returns[-1]/np.std(np.diff(rf_strategy_returns)),\n",
        "                               lstm_strategy_returns[-1]/np.std(np.diff(lstm_strategy_returns))]\n",
        "            })\n",
        "\n",
        "            st.dataframe(returns_df.style.highlight_max(subset=['Total Return (%)', 'Sharpe Ratio'], color='lightgreen')\n",
        "                        .highlight_min(subset=['Volatility (%)'], color='lightgreen')\n",
        "                        .format({'Total Return (%)': '{:.2f}%', 'Volatility (%)': '{:.2f}%', 'Sharpe Ratio': '{:.2f}'}))\n",
        "\n",
        "except Exception as e:\n",
        "    st.error(f\"An error occurred: {e}\")\n",
        "    st.info(\"Please check your internet connection or try a different stock symbol.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2vgL569nURKNBn1P7TxWluwuJJO_TUNJmSHYkZtzJM15yMTC\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paHt84qB98oB",
        "outputId": "a662e2b8-ed7f-4e44-c0c6-4cdf18f0674a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install streamlit pyngrok --quiet\n",
        "!npm install localtunnel -g\n",
        "\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "\n",
        "process = subprocess.Popen([\n",
        "    \"streamlit\", \"run\", \"dashboard.py\",\n",
        "    \"--server.port\", \"8501\",\n",
        "    \"--server.headless\", \"true\",\n",
        "    \"--server.enableCORS\", \"false\"\n",
        "], stdout=subprocess.DEVNULL)\n",
        "\n",
        "\n",
        "time.sleep(10)\n",
        "\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "\n",
        "ngrok.set_auth_token(\"2vgL569nURKNBn1P7TxWluwuJJO_TUNJmSHYkZtzJM15yMTC\")\n",
        "\n",
        "\n",
        "public_url = ngrok.connect(addr=\"8501\", proto=\"http\", bind_tls=True)\n",
        "print(f\"Dashboard accessible at: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwtYeyqh_yU_",
        "outputId": "26c75433-4364-4916-ff30-ef0df508475b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\n",
            "added 22 packages in 4s\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0KDashboard accessible at: NgrokTunnel: \"https://03b6-34-80-35-45.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "\n",
        "\n",
        "NGROK_AUTHTOKEN = \"2vgL569nURKNBn1P7TxWluwuJJO_TUNJmSHYkZtzJM15yMTC\"\n",
        "\n",
        "\n",
        "\n",
        "ngrok.set_auth_token(NGROK_AUTHTOKEN)\n",
        "\n",
        "\n",
        "\n",
        "public_url = ngrok.connect(addr=\"8501\", proto=\"http\")\n",
        "print(f\"Streamlit app is live at: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcX6s-ARAOAU",
        "outputId": "134e728c-18f5-4e34-bc10-c4298f925219"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://4a88-34-80-35-45.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!ps aux | grep streamlit\n",
        "\n",
        "\n",
        "!netstat -tuln | grep ':8501'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a92koEqlCays",
        "outputId": "274c90e9-6742-4903-e895-72902f86aec8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root         940  6.4  0.0      0     0 ?        Z    16:51   0:00 [streamlit] <defunct>\n",
            "root        1013  0.0  0.0   7376  3484 ?        S    16:51   0:00 /bin/bash -c ps aux | grep streamlit\n",
            "root        1015  0.0  0.0   6484  2284 ?        S    16:51   0:00 grep streamlit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "\n",
        "zombie_pid = 6034\n",
        "ppid_command = [\"ps\", \"-o\", \"ppid=\", \"-p\", str(zombie_pid)]\n",
        "\n",
        "\n",
        "\n",
        "result = subprocess.run(ppid_command, stdout=subprocess.PIPE, text=True)\n",
        "ppid = result.stdout.strip()\n",
        "\n",
        "if ppid:\n",
        "    print(f\"Parent Process ID (PPID): {ppid}\")\n",
        "else:\n",
        "    print(\"Failed to retrieve PPID. Ensure the zombie PID is correct.\")\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "if ppid:\n",
        "    try:\n",
        "\n",
        "\n",
        "        os.system(f\"kill -9 {ppid}\")\n",
        "        print(f\"Successfully killed parent process with PPID: {ppid}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error while killing parent process: {e}\")\n",
        "else:\n",
        "    print(\"Cannot kill parent process. PPID not found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvidS1S_DTIG",
        "outputId": "9fe84ae0-6a18-46e7-e479-e48410e947ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve PPID. Ensure the zombie PID is correct.\n",
            "Cannot kill parent process. PPID not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ps aux | grep 'Z'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3frWhEZDl21",
        "outputId": "655b0276-310a-45d5-faf4-188ebb973e56"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\n",
            "root          69 11.8  0.0      0     0 ?        Z    16:48   0:21 [python3] <defunct>\n",
            "root         940  6.4  0.0      0     0 ?        Z    16:51   0:00 [streamlit] <defunct>\n",
            "root        1020  0.0  0.0   7376  3468 ?        S    16:51   0:00 /bin/bash -c ps aux | grep 'Z'\n",
            "root        1022  0.0  0.0   6484  2296 ?        S    16:51   0:00 grep Z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pkill -9 streamlit\n"
      ],
      "metadata": {
        "id": "iM7DNwk8DsE8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ps -o ppid= -p 6034\n",
        "\n",
        "\n",
        "\n",
        "!kill -9 6668\n",
        "!kill -9 6670"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1y50P_OCrbt",
        "outputId": "13342e6b-539f-4dcf-fcc9-d168e746bb57"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: kill: (6668) - No such process\n",
            "/bin/bash: line 1: kill: (6670) - No such process\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ps aux | grep streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au6SRrgQDC6I",
        "outputId": "a9d87b14-e2b6-4b3f-cb7e-4450c2f373d9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root         940  6.4  0.0      0     0 ?        Z    16:51   0:00 [streamlit] <defunct>\n",
            "root        1055  0.0  0.0   7376  3520 ?        S    16:51   0:00 /bin/bash -c ps aux | grep streamlit\n",
            "root        1057  0.0  0.0   6484  2336 ?        S    16:51   0:00 grep streamlit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "\n",
        "process = subprocess.Popen([\n",
        "    \"streamlit\", \"run\", \"dashboard.py\",\n",
        "    \"--server.port\", \"8501\",\n",
        "    \"--server.headless\", \"true\",\n",
        "    \"--server.address\", \"0.0.0.0\"\n",
        "], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "\n",
        "time.sleep(15)\n",
        "\n",
        "\n",
        "ngrok.set_auth_token(\"2vgL569nURKNBn1P7TxWluwuJJO_TUNJmSHYkZtzJM15yMTC\")\n",
        "\n",
        "\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(f\"Streamlit app is live at: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQi3RrlWDE9t",
        "outputId": "b3fe6c86-4847-4709-b57d-33422a7335da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at: NgrokTunnel: \"https://ca37-34-80-35-45.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!ps aux | grep streamlit\n",
        "\n",
        "!netstat -tuln | grep ':8501'\n",
        "\n",
        "!curl -I http://localhost:8501\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYDK8sk3DINZ",
        "outputId": "51babce2-7025-4c81-93e2-53636fdc3448"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root        1062  4.6  0.0      0     0 ?        Z    16:51   0:00 [streamlit] <defunct>\n",
            "root        1134  0.0  0.0   7376  3448 ?        S    16:52   0:00 /bin/bash -c ps aux | grep streamlit\n",
            "root        1136  0.0  0.0   6484  2304 ?        S    16:52   0:00 grep streamlit\n",
            "curl: (7) Failed to connect to localhost port 8501 after 0 ms: Connection refused\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "\n",
        "\n",
        "tunnels = ngrok.get_tunnels()\n",
        "print(\"Active Tunnels:\", tunnels)\n",
        "\n",
        "\n",
        "\n",
        "for tunnel in tunnels:\n",
        "    ngrok.disconnect(tunnel.public_url)\n",
        "    print(f\"Closed tunnel: {tunnel.public_url}\")\n",
        "\n",
        "\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(f\"New tunnel: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2GLhWKaEdHN",
        "outputId": "d5fd2d28-5644-4435-b5e5-a67ecf712934"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-04-13T16:53:24+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-cf061786-2223-4e94-976d-d5b87b13f567 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Active Tunnels: [<NgrokTunnel: \"https://03b6-34-80-35-45.ngrok-free.app\" -> \"http://localhost:8501\">, <NgrokTunnel: \"https://4a88-34-80-35-45.ngrok-free.app\" -> \"http://localhost:8501\">, <NgrokTunnel: \"https://ca37-34-80-35-45.ngrok-free.app\" -> \"http://localhost:8501\">]\n",
            "Closed tunnel: https://03b6-34-80-35-45.ngrok-free.app\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2025-04-13T16:53:24+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-2debc48a-f1be-4850-a830-d46867face42 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-04-13T16:53:25+0000 lvl=warn msg=\"Stopping forwarder\" name=http-8501-8d31276b-2e45-43b2-8707-867091925e4a acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closed tunnel: https://4a88-34-80-35-45.ngrok-free.app\n",
            "Closed tunnel: https://ca37-34-80-35-45.ngrok-free.app\n",
            "New tunnel: NgrokTunnel: \"https://d081-34-80-35-45.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "\n",
        "process = subprocess.Popen([\n",
        "    \"streamlit\", \"run\", \"dashboard.py\",\n",
        "    \"--server.port\", \"8501\",\n",
        "    \"--server.headless\", \"true\",\n",
        "    \"--server.address\", \"0.0.0.0\"\n",
        "])\n",
        "\n",
        "\n",
        "time.sleep(15)\n",
        "\n",
        "\n",
        "\n",
        "ngrok.set_auth_token(\"2vgL569nURKNBn1P7TxWluwuJJO_TUNJmSHYkZtzJM15yMTC\")\n",
        "\n",
        "\n",
        "\n",
        "public_url = ngrok.connect(8501, \"http\")\n",
        "print(f\"Access dashboard at: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ituffAr6CkW2",
        "outputId": "3bca76cd-d629-4627-a243-aa118ac1fc4a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Access dashboard at: NgrokTunnel: \"https://951b-34-80-35-45.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ]
}